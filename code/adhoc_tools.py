import argparse
import dataclasses
import glob
import logging
import os
import re
from datetime import datetime

import data
import db
import geojson
import requests
import suburbs
from bs4 import BeautifulSoup


def get_nbn_suburb_dates():
    """Parse a NBN web page to get a list of all suburb upgrade dates."""
    URL = "https://www.nbnco.com.au/residential/upgrades/more-fibre"
    logging.info("Fetching list of suburbs from NBN website...")
    content = requests.get(URL).content

    results = {}

    soup = BeautifulSoup(content, "html.parser")
    for state_element in soup.find(id="accordion-c467de9e93").find_all("div", class_="cmp-accordion__item"):
        state = state_element.find("span", class_="cmp-accordion__title").text
        results[state] = {}
        for p in state_element.find("div", class_="cmp-text").find_all("p"):
            for suburb, date in re.findall(r"^(.*) - from (\w+ \d{4})", p.text, flags=re.MULTILINE):
                results[state][suburb] = date

    # Convert to consistent state/suburb format
    return {state: {s.title(): d for s, d in suburb_list.items()} for state, suburb_list in results.items()}


def get_nbn_suburb_list():
    """Parse a NBN web page to get a list of all suburbs announced for upgrades."""
    URL = (
        "https://www.nbnco.com.au/corporate-information/media-centre/media-statements/nbnco-announces-suburbs-and"
        "-towns-where-an-additional-ninty-thousand-homes-and-businesses-will-become-eligible-for-fibre-upgrades"
    )
    logging.info("Fetching list of suburb dates from NBN website...")
    content = requests.get(URL).content

    results = {}

    soup = BeautifulSoup(content, "html.parser")
    for state_element in soup.find_all("div", class_="cmp-accordion__item"):
        state = state_element.find("span", class_="cmp-accordion__title").text
        results[state] = []
        for p in state_element.find("div", class_="cmp-text").find_all("p"):
            if p.text.startswith("Announced "):
                continue
            # remove extra text, and sanitise suburb names
            suburbs = [
                re.sub(
                    r"( \(ADDITIONAL FOOTPRINT\)|ADDITIONAL AREAS OF | \(4350\))",
                    "",
                    suburb.strip("*#.\xa0\r\n").replace("â€™", "'"),
                    flags=re.IGNORECASE,
                )
                for suburb in re.split(r", ?", p.text)
            ]
            results[state].extend(suburbs)

    # Convert to consistent state/suburb format
    return {data.STATES_MAP[state]: [s.title() for s in suburbs] for state, suburbs in results.items()}


def get_db_suburb_list():
    """Get list of all states and suburbs from the database"""
    xdb = db.connect_to_db(args)
    db_suburb_counts = xdb.get_counts_by_suburb()
    return {
        state: [s.title() for s in sorted(suburb_counts.keys())] for state, suburb_counts in db_suburb_counts.items()
    }


def rebuild_status_file():
    """Fetch a list of all suburbs from DB, augment with announced+dates, and completed results"""
    # Load list of all suburbs from DB
    db_suburbs = get_db_suburb_list()
    # geojson.write_json_file("results/db-counts.json", db_suburbs)
    # db_suburbs = geojson.read_json_file("results/db-counts.json")

    # Load list of all announced suburbs from NBN website
    announced_suburbs = get_nbn_suburb_list()
    # geojson.write_json_file("results/announced.json", announced_suburbs)
    # with open("results/announced.json", "r", encoding="utf-8") as file:
    #     announced_suburbs = json.load(file)
    # announced_suburbs = geojson.read_json_file("results/announced.json")

    # Load list of all suburb dates from NBN website
    suburb_dates = get_nbn_suburb_dates()
    # geojson.write_json_file("results/suburb-dates.json", suburb_dates)
    # suburb_dates = geojson.read_json_file("results/suburb-dates.json")

    # TODO: Townsville not in DB. Why?  Two similar names included

    # add OT
    if "OT" not in announced_suburbs:
        announced_suburbs["OT"] = []
    if "OT" not in suburb_dates:
        suburb_dates["OT"] = {}

    # convert to sets for faster operation
    announced_suburbs = {state: set(suburb_list) for state, suburb_list in announced_suburbs.items()}
    db_suburbs = {state: set(suburb_list) for state, suburb_list in db_suburbs.items()}

    all_suburbs = {}  # state -> List[Suburb]
    for state, suburb_list in db_suburbs.items():
        all_suburbs[state] = []
        for suburb in suburb_list:
            announced = suburb in announced_suburbs[state]
            announced_date = suburb_dates[state].get(suburb, None)
            processed_date = geojson.get_geojson_file_generated(suburb, state)
            xsuburb = data.Suburb(
                name=suburb,
                state=state,
                announced=announced,
                announced_date=announced_date,
                processed_date=processed_date,
            )
            all_suburbs[state].append(xsuburb)

            if announced and announced_date is None:
                print(f"Announced {suburb}, {state} - but no date")

    write_all_suburbs(all_suburbs)


def write_all_suburbs(all_suburbs: dict):  # Dict[str, List[data.Suburb]]
    """Write the list of all suburbs to a file."""

    def _suburb_to_dict(s: data.Suburb) -> dict:
        d = dataclasses.asdict(s)
        if d["processed_date"]:
            d["processed_date"] = d["processed_date"].isoformat()
        return d

    all_suburbs_dicts = {
        state: [_suburb_to_dict(xsuburb) for xsuburb in suburbs_list] for state, suburbs_list in all_suburbs.items()
    }
    geojson.write_json_file("results/all-suburbs.json", all_suburbs_dicts)


def read_all_suburbs() -> dict:
    """Read the list of all suburbs from a file."""

    def _dict_to_suburb(d: dict) -> data.Suburb:
        d["processed_date"] = datetime.fromisoformat(d["processed_date"]) if d["processed_date"] else None
        return data.Suburb(**d)

    results = geojson.read_json_file("results/all-suburbs.json")
    return {state: [_dict_to_suburb(d) for d in suburbs_list] for state, suburbs_list in results.items()}


def resort_results():
    """Sort every one of the previously created geojson files by gnaf_pid"""
    for state in data.STATES:
        for file in glob.glob(f"results/{state}/*.geojson"):
            print(file)
            result = geojson.read_json_file(file)
            result["features"] = sorted(result["features"], key=lambda x: x["properties"]["gnaf_pid"])
            geojson.write_json_file(file, result, indent=1)


def add_to_announced_suburbs():
    """Add all the suburbs announced with dates to the current list"""
    all_suburb_dates = get_nbn_suburb_dates()
    announced_suburbs = suburbs.get_listed_suburbs()  # Dict[str, List[str]] - capitals only
    for state, suburb_dates in all_suburb_dates.items():
        for suburb, date in suburb_dates.items():
            suburb = suburb.upper()
            if suburb not in announced_suburbs[state]:
                logging.info("+%s", suburb)
                announced_suburbs[state].append(suburb)
            else:
                logging.info("~%s", suburb)
        announced_suburbs[state].sort()
    geojson.write_json_file("results/suburbs.json", {"states": announced_suburbs})


def get_suburb_extents():
    xdb = db.connect_to_db(args)
    logging.info("Getting extents")
    result = xdb.get_extents_by_suburb()
    logging.info("Writing extents")
    # pprint.pprint(result)
    geojson.write_json_file("results/suburb-extents.json", result)


if __name__ == "__main__":
    LOGLEVEL = os.environ.get("LOGLEVEL", "INFO").upper()
    logging.basicConfig(level=LOGLEVEL, format="%(asctime)s %(levelname)s %(threadName)s %(message)s")

    parser = argparse.ArgumentParser(description="Emit a summary of progress against the list of suburbs in the DB.")
    db.add_db_arguments(parser)
    args = parser.parse_args()

    # resort_results()
    # add_to_announced_suburbs()
    get_suburb_extents()

    # rebuild_status_file()
    # blah = read_all_suburbs()
    # blah = geojson.read_json_file("results/all-suburbs.json")

    # geojson.write_json_file("results/suburb-dates.json", get_nbn_suburb_dates())

    # update_suburb_dates()
    # compare_suburb_lists()
    # compare_db_suburbs()
